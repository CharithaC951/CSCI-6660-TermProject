{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5bc1ec-cbb5-4085-b327-5fd795af78d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from pycocotools.coco import COCO\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Path to COCO dataset annotations and images\n",
    "annotations_path = r\"C:\\Users\\dnave\\Downloads\\COCO Dataset\\coco2017\\annotations\\instances_train2017.json\"\n",
    "images_path =r\"C:\\Users\\dnave\\Downloads\\COCO Dataset\\coco2017\\train2017\"\n",
    "\n",
    "# Load COCO dataset\n",
    "coco = COCO(annotations_path)\n",
    "image_ids = coco.getImgIds()\n",
    "\n",
    "# Define DQN agent class\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = []\n",
    "        self.gamma = 0.99  # Discount factor\n",
    "        self.epsilon = 1.0  # Exploration rate\n",
    "        self.epsilon_min = 0.1\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.learning_rate = 0.001\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, activation='relu', input_shape=(self.state_size,)))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "\n",
    "    '''def build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(24, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(24, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=self.learning_rate))\n",
    "\n",
    "        return model'''\n",
    "    \n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.max(self.model.predict(next_state)[0])\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "\n",
    "# Define IOU function to compute Intersection over Union (IoU) for reward calculation\n",
    "def iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "# Define the environment interaction function\n",
    "def get_training_data():\n",
    "    images = []\n",
    "    bbs = []\n",
    "    labels = []\n",
    "    for img_id in image_ids[:10]:  # Load 10 images for training (for example)\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        img_path = f\"{images_path}/{img_info['file_name']}\"\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img_resized = cv2.resize(img, (224, 224))\n",
    "\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "        for ann in anns:\n",
    "            bbox = ann['bbox']\n",
    "            x1, y1, width, height = bbox\n",
    "            x2, y2 = x1 + width, y1 + height\n",
    "            bbox_converted = [x1, y1, x2, y2]\n",
    "\n",
    "            images.append(img_resized)\n",
    "            bbs.append(bbox_converted)\n",
    "            labels.append(ann['category_id'])\n",
    "\n",
    "    return np.array(images), np.array(bbs), np.array(labels)\n",
    "\n",
    "# Initialize agent and training data\n",
    "state_size = 224 * 224 * 3  # Flatten image size (224x224x3)\n",
    "action_size = 10  # Assume there are 10 possible bounding boxes to choose from (as an example)\n",
    "agent = DQNAgent(state_size, action_size)\n",
    "\n",
    "images_train, bbs_train, labels_train = get_training_data()\n",
    "\n",
    "# Training loop\n",
    "max_episodes = 1000\n",
    "batch_size = 32\n",
    "\n",
    "for e in range(max_episodes):\n",
    "    state = np.reshape(images_train[e % len(images_train)], [1, state_size])\n",
    "    for time in range(100):  # Maximum steps per episode\n",
    "        action = agent.act(state)\n",
    "        \n",
    "        # Here we simulate \"correct action\" with IoU as reward. In real implementation, use actual environment.\n",
    "        chosen_bbox = bbs_train[action]  # Chosen bounding box by agent\n",
    "        ground_truth_bbox = bbs_train[e % len(bbs_train)]  # For simplicity, use same image as ground truth\n",
    "        reward = iou(chosen_bbox, ground_truth_bbox)\n",
    "\n",
    "        # Next state (in this simplified case, it remains the same)\n",
    "        next_state = state\n",
    "        \n",
    "        done = False  # Define when an episode ends\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)\n",
    "\n",
    "    if e % 10 == 0:\n",
    "        print(f\"Episode {e}/{max_episodes} - Epsilon: {agent.epsilon:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f613903-4f16-4029-9055-0a031f1a3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.model.save(\"dqn_object_detector.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d74c78-65fd-4916-99c6-2c5584f89bee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"dqn_object_detector.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0551acaf-0fe2-44d8-a773-be72c42165cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "import tensorflow as tf\n",
    "\n",
    "# Paths to your COCO dataset\n",
    "annotations_path = r\"C:\\Users\\dnave\\Downloads\\COCO Dataset\\coco2017\\annotations\\instances_train2017.json\"\n",
    "images_path = r\"C:\\Users\\dnave\\Downloads\\COCO Dataset\\coco2017\\train2017\"\n",
    "\n",
    "# Load COCO dataset\n",
    "coco = COCO(annotations_path)\n",
    "\n",
    "# Map category_id to object names\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "category_map = {cat['id']: cat['name'] for cat in categories}\n",
    "\n",
    "# Function to query and highlight the specified object\n",
    "def highlight_object(image_path, object_name, model):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"Error loading image.\")\n",
    "        return\n",
    "    \n",
    "    image_resized = cv2.resize(image, (224, 224))  # Resize for the DQN model\n",
    "    state = np.reshape(image_resized, [1, 224 * 224 * 3])  # Flatten image\n",
    "    \n",
    "    # Find category_id for the specified object\n",
    "    category_id = [k for k, v in category_map.items() if v == object_name]\n",
    "    if not category_id:\n",
    "        print(f\"Object '{object_name}' not found in the COCO categories.\")\n",
    "        return\n",
    "\n",
    "    # Use DQN model to predict bounding box\n",
    "    predicted_action = model.predict(state)\n",
    "    bbox = bbs_train[int(predicted_action[0])]  # Assuming bbox is stored during training\n",
    "\n",
    "    # Highlight the bounding box on the image\n",
    "    x1, y1, x2, y2 = map(int, bbox)\n",
    "    highlighted_image = cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    highlighted_image = cv2.putText(\n",
    "        highlighted_image, \n",
    "        object_name, \n",
    "        (x1, y1 - 10), \n",
    "        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "        0.9, \n",
    "        (0, 255, 0), \n",
    "        2\n",
    "    )\n",
    "\n",
    "    # Display the image\n",
    "    cv2.imshow(\"Highlighted Object\", highlighted_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Load your trained model\n",
    "agent = DQNAgent(state_size=224 * 224 * 3, action_size=10)  # Reuse your DQNAgent class\n",
    "agent.model = tf.keras.models.load_model(\"dqn_object_detector.h5\")\n",
    "\n",
    "# Test the function\n",
    "test_image_path = r\"C:\\Users\\dnave\\Downloads\\COCO Dataset\\coco2017\\train2017\\example_image.jpg\"  # Replace with an actual image path\n",
    "highlight_object(test_image_path, \"person\", agent.model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6441ca25-1fac-475b-ac40-e56ad2fdd73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_object(image_path, object_name, model):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"Error loading image. Check the path:\", image_path)\n",
    "        return\n",
    "    \n",
    "    print(\"Image loaded successfully.\")\n",
    "    image_resized = cv2.resize(image, (224, 224))\n",
    "    state = np.reshape(image_resized, [1, 224 * 224 * 3])\n",
    "\n",
    "    # Find category_id\n",
    "    category_id = [k for k, v in category_map.items() if v == object_name]\n",
    "    if not category_id:\n",
    "        print(f\"Object '{object_name}' not found in COCO categories.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Category ID for {object_name}: {category_id}\")\n",
    "\n",
    "    # Predict bounding box\n",
    "    predicted_action = model.predict(state)\n",
    "    print(\"Model prediction:\", predicted_action)\n",
    "    \n",
    "    if len(bbs_train) <= int(predicted_action[0]):\n",
    "        print(\"Predicted action index out of range.\")\n",
    "        return\n",
    "\n",
    "    bbox = bbs_train[int(predicted_action[0])]\n",
    "    print(\"Predicted bounding box:\", bbox)\n",
    "\n",
    "    # Draw rectangle\n",
    "    try:\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        highlighted_image = cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        highlighted_image = cv2.putText(\n",
    "            highlighted_image, \n",
    "            object_name, \n",
    "            (x1, y1 - 10), \n",
    "            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "            0.9, \n",
    "            (0, 255, 0), \n",
    "            2\n",
    "        )\n",
    "        print(\"Bounding box drawn successfully.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error drawing bounding box:\", e)\n",
    "        return\n",
    "\n",
    "    # Display the image\n",
    "    cv2.imshow(\"Highlighted Object\", highlighted_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
