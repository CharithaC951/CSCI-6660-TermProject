{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0e05487-cb55-4580-b452-4c7b4ef3a6dc",
   "metadata": {},
   "source": [
    "### Faster RCNN and SSD for multiple objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4535417-80ef-4d65-99af-a84245aba758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, ssd300_vgg16\n",
    "from torchvision.models.detection.faster_rcnn import FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection.ssd import SSD300_VGG16_Weights\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# COCO Dataset labels\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '', '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',\n",
    "    'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',\n",
    "    'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle',\n",
    "    'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "# Path to test images directory\n",
    "IMAGE_DIR = \"C:\\\\Users\\\\chari\\\\Downloads\\\\test2017\\\\test2017\"\n",
    "\n",
    "# Path to COCO annotations (for validation)\n",
    "ANNOTATION_PATH = \"C:\\\\Users\\\\chari\\\\Downloads\\\\annotations_trainval2017\\\\annotations\\\\instances_val2017.json\"\n",
    "\n",
    "# Load COCO annotations\n",
    "with open(ANNOTATION_PATH, 'r') as f:\n",
    "    coco_annotations = json.load(f)\n",
    "\n",
    "# Create a dictionary for ground truth labels and boxes\n",
    "ground_truth = {}\n",
    "for annotation in coco_annotations['annotations']:\n",
    "    image_id = annotation['image_id']\n",
    "    category_id = annotation['category_id']\n",
    "    bbox = annotation['bbox']\n",
    "    if image_id not in ground_truth:\n",
    "        ground_truth[image_id] = []\n",
    "    ground_truth[image_id].append((category_id, bbox))\n",
    "\n",
    "# Check if there are any .jpg files in the directory\n",
    "image_files = [file_name for file_name in os.listdir(IMAGE_DIR) if file_name.endswith(\".jpg\")]\n",
    "if len(image_files) == 0:\n",
    "    print(f\"No .jpg image files found in {IMAGE_DIR}. Please check the folder.\")\n",
    "else:\n",
    "    print(f\"Found {len(image_files)} .jpg image(s).\")\n",
    "\n",
    "# Load models with updated weights parameter\n",
    "faster_rcnn = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT).eval()\n",
    "ssd = ssd300_vgg16(weights=SSD300_VGG16_Weights.DEFAULT).eval()\n",
    "\n",
    "# Helper function to filter predictions based on confidence threshold\n",
    "def get_filtered_predictions(predictions, scores, threshold=0.5):\n",
    "    \"\"\"Filter predictions based on confidence score threshold.\"\"\"\n",
    "    return [pred for pred, score in zip(predictions, scores) if score >= threshold]\n",
    "\n",
    "# Function to calculate Intersection over Union (IoU)\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Compute Intersection over Union (IoU) between two boxes.\"\"\"\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "\n",
    "    # Compute the coordinates of the intersection rectangle\n",
    "    inter_x1 = max(x1, x2)\n",
    "    inter_y1 = max(y1, y2)\n",
    "    inter_x2 = min(x1 + w1, x2 + w2)\n",
    "    inter_y2 = min(y1 + h1, y2 + h2)\n",
    "\n",
    "    # Compute area of intersection\n",
    "    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
    "\n",
    "    # Compute area of both boxes\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "\n",
    "    # Compute union area\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    # Compute IoU\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "# Function to visualize predictions on the image\n",
    "def visualize_predictions(image, boxes, scores, labels, model_name):\n",
    "    \"\"\"Overlay bounding boxes, labels, and scores on the image.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        if score > 0.5:  # Only display detections with confidence > 0.5\n",
    "            if label < len(COCO_INSTANCE_CATEGORY_NAMES):\n",
    "                label_name = COCO_INSTANCE_CATEGORY_NAMES[label]\n",
    "            else:\n",
    "                label_name = \"Unknown\"\n",
    "            box = [int(coord) for coord in box]\n",
    "            draw.rectangle(box, outline=\"red\", width=3)\n",
    "            draw.text((box[0], box[1]), f\"{label_name} {score:.2f}\", fill=\"red\")\n",
    "    return image\n",
    "\n",
    "# Process and visualize predictions for all images in the directory\n",
    "faster_rcnn_accuracies = []\n",
    "ssd_accuracies = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_name in image_files:\n",
    "        img_path = os.path.join(IMAGE_DIR, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Open image\n",
    "        \n",
    "        print(f\"Processing image: {img_name}\")\n",
    "\n",
    "        # Convert image to tensor\n",
    "        img_tensor = F.to_tensor(img)\n",
    "\n",
    "        # Faster R-CNN predictions\n",
    "        faster_rcnn_output = faster_rcnn([img_tensor])[0]\n",
    "        faster_rcnn_boxes = faster_rcnn_output['boxes'].cpu().numpy()\n",
    "        faster_rcnn_scores = faster_rcnn_output['scores'].cpu().numpy()\n",
    "        faster_rcnn_labels = faster_rcnn_output['labels'].cpu().numpy()\n",
    "\n",
    "        # SSD predictions\n",
    "        ssd_output = ssd([img_tensor])[0]\n",
    "        ssd_boxes = ssd_output['boxes'].cpu().numpy()\n",
    "        ssd_scores = ssd_output['scores'].cpu().numpy()\n",
    "        ssd_labels = ssd_output['labels'].cpu().numpy()\n",
    "\n",
    "        # Get ground truth for the image\n",
    "        image_id = int(img_name.split('.')[0])\n",
    "        gt_data = ground_truth.get(image_id, [])\n",
    "\n",
    "        # Filter predictions for both models (confidence threshold)\n",
    "        faster_rcnn_filtered = get_filtered_predictions(faster_rcnn_labels, faster_rcnn_scores, threshold=0.5)\n",
    "        ssd_filtered = get_filtered_predictions(ssd_labels, ssd_scores, threshold=0.5)\n",
    "\n",
    "        # Evaluate accuracy based on IoU threshold\n",
    "        def calculate_accuracy(gt_data, pred_data):\n",
    "            correct_preds = 0\n",
    "            for gt_category, gt_bbox in gt_data:\n",
    "                for pred_category, pred_bbox in pred_data:\n",
    "                    iou = compute_iou(gt_bbox, pred_bbox)\n",
    "                    if iou > 0.5:  # If IoU > 0.5, count as a correct prediction\n",
    "                        correct_preds += 1\n",
    "            return correct_preds / len(gt_data) if len(gt_data) > 0 else 0\n",
    "\n",
    "        # Accuracy for Faster R-CNN\n",
    "        faster_rcnn_accuracy = calculate_accuracy(gt_data, list(zip(faster_rcnn_labels, faster_rcnn_boxes)))\n",
    "        faster_rcnn_accuracies.append(faster_rcnn_accuracy)\n",
    "\n",
    "        # Accuracy for SSD\n",
    "        ssd_accuracy = calculate_accuracy(gt_data, list(zip(ssd_labels, ssd_boxes)))\n",
    "        ssd_accuracies.append(ssd_accuracy)\n",
    "\n",
    "        # Visualize Faster R-CNN predictions\n",
    "        faster_rcnn_img = visualize_predictions(img.copy(), faster_rcnn_boxes, faster_rcnn_scores, faster_rcnn_labels, \"Faster R-CNN\")\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(faster_rcnn_img)\n",
    "        plt.title(f\"Faster R-CNN Predictions for {img_name}\")\n",
    "        plt.show()\n",
    "\n",
    "        # Visualize SSD predictions\n",
    "        ssd_img = visualize_predictions(img.copy(), ssd_boxes, ssd_scores, ssd_labels, \"SSD\")\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(ssd_img)\n",
    "        plt.title(f\"SSD Predictions for {img_name}\")\n",
    "        plt.show()\n",
    "\n",
    "# Print average accuracy for both models\n",
    "print(f\"Average accuracy for Faster R-CNN: {np.mean(faster_rcnn_accuracies):.2f}\")\n",
    "print(f\"Average accuracy for SSD: {np.mean(ssd_accuracies):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5489d0-e61d-4bdd-b756-321725648505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, ssd300_vgg16\n",
    "from torchvision.models.detection.faster_rcnn import FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection.ssd import SSD300_VGG16_Weights\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# COCO Dataset labels\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '', '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',\n",
    "    'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',\n",
    "    'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle',\n",
    "    'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "# Paths\n",
    "IMAGE_DIR = \"C:\\\\Users\\\\chari\\\\Downloads\\\\val2017\\\\val2017\"  # Replace with the path to the `val2017` images\n",
    "ANNOTATION_PATH = \"C:\\\\Users\\\\chari\\\\Downloads\\\\annotations_trainval2017\\\\annotations\\\\instances_val2017.json\"  # Replace with the path to `instances_val2017.json`\n",
    "\n",
    "# Load COCO annotations\n",
    "with open(ANNOTATION_PATH, 'r') as f:\n",
    "    coco_annotations = json.load(f)\n",
    "\n",
    "# Create a dictionary for ground truth labels and boxes\n",
    "ground_truth = {}\n",
    "for annotation in coco_annotations['annotations']:\n",
    "    image_id = annotation['image_id']\n",
    "    category_id = annotation['category_id']\n",
    "    bbox = annotation['bbox']  # Format: [x, y, width, height]\n",
    "    if image_id not in ground_truth:\n",
    "        ground_truth[image_id] = []\n",
    "    ground_truth[image_id].append((category_id, bbox))\n",
    "\n",
    "# Get the list of images in val2017\n",
    "image_files = [file_name for file_name in os.listdir(IMAGE_DIR) if file_name.endswith(\".jpg\")]\n",
    "\n",
    "# Select a random subset of 100 images\n",
    "random.seed(42)  # For reproducibility\n",
    "selected_images = random.sample(image_files, min(200, len(image_files)))\n",
    "\n",
    "# Load models\n",
    "faster_rcnn = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT).eval()\n",
    "ssd = ssd300_vgg16(weights=SSD300_VGG16_Weights.DEFAULT).eval()\n",
    "\n",
    "# Helper functions\n",
    "def get_filtered_predictions(predictions, scores, threshold=0.5):\n",
    "    \"\"\"Filter predictions based on confidence score threshold.\"\"\"\n",
    "    return [pred for pred, score in zip(predictions, scores) if score >= threshold]\n",
    "\n",
    "def compute_iou(box1, box2):\n",
    "    \"\"\"Compute Intersection over Union (IoU) between two boxes.\"\"\"\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "\n",
    "    # Convert width and height to coordinates\n",
    "    x1_max, y1_max = x1 + w1, y1 + h1\n",
    "    x2_max, y2_max = x2 + w2, y2 + h2\n",
    "\n",
    "    # Compute the coordinates of the intersection rectangle\n",
    "    inter_x1 = max(x1, x2)\n",
    "    inter_y1 = max(y1, y2)\n",
    "    inter_x2 = min(x1_max, x2_max)\n",
    "    inter_y2 = min(y1_max, y2_max)\n",
    "\n",
    "    # Compute area of intersection\n",
    "    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
    "\n",
    "    # Compute area of both boxes\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "\n",
    "    # Compute union area\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    # Compute IoU\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "# Evaluation\n",
    "faster_rcnn_accuracies = []\n",
    "ssd_accuracies = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img_name in selected_images:\n",
    "        img_path = os.path.join(IMAGE_DIR, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Open image\n",
    "        img_tensor = F.to_tensor(img)  # Convert to tensor\n",
    "\n",
    "        print(f\"Processing image: {img_name}\")\n",
    "\n",
    "        # Get ground truth for the image\n",
    "        image_id = int(img_name.split('.')[0])\n",
    "        gt_data = ground_truth.get(image_id, [])\n",
    "\n",
    "        # Faster R-CNN predictions\n",
    "        faster_rcnn_output = faster_rcnn([img_tensor])[0]\n",
    "        faster_rcnn_boxes = faster_rcnn_output['boxes'].cpu().numpy()\n",
    "        faster_rcnn_scores = faster_rcnn_output['scores'].cpu().numpy()\n",
    "        faster_rcnn_labels = faster_rcnn_output['labels'].cpu().numpy()\n",
    "\n",
    "        # SSD predictions\n",
    "        ssd_output = ssd([img_tensor])[0]\n",
    "        ssd_boxes = ssd_output['boxes'].cpu().numpy()\n",
    "        ssd_scores = ssd_output['scores'].cpu().numpy()\n",
    "        ssd_labels = ssd_output['labels'].cpu().numpy()\n",
    "\n",
    "        # Evaluate accuracy based on IoU threshold\n",
    "        def calculate_accuracy(gt_data, pred_labels, pred_boxes):\n",
    "            correct_preds = 0\n",
    "            for gt_category, gt_bbox in gt_data:\n",
    "                for pred_label, pred_bbox in zip(pred_labels, pred_boxes):\n",
    "                    iou = compute_iou(gt_bbox, pred_bbox)\n",
    "                    if iou > 0.5 and gt_category == pred_label:\n",
    "                        correct_preds += 1\n",
    "            return correct_preds / len(gt_data) if len(gt_data) > 0 else 0\n",
    "\n",
    "        # Accuracy for Faster R-CNN\n",
    "        faster_rcnn_accuracy = calculate_accuracy(gt_data, faster_rcnn_labels, faster_rcnn_boxes)\n",
    "        faster_rcnn_accuracies.append(faster_rcnn_accuracy)\n",
    "\n",
    "        # Accuracy for SSD\n",
    "        ssd_accuracy = calculate_accuracy(gt_data, ssd_labels, ssd_boxes)\n",
    "        ssd_accuracies.append(ssd_accuracy)\n",
    "\n",
    "# Print average accuracy for both models\n",
    "print(f\"Average accuracy for Faster R-CNN: {np.mean(faster_rcnn_accuracies):.2f}\")\n",
    "print(f\"Average accuracy for SSD: {np.mean(ssd_accuracies):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf938f06-29a6-4dd8-be99-f54187524b3d",
   "metadata": {},
   "source": [
    "### Faster RCNN and SSD with single object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4fe1d-07cd-4c86-9960-d5872c2b0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn, ssd300_vgg16\n",
    "from torchvision.models.detection.faster_rcnn import FasterRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection.ssd import SSD300_VGG16_Weights\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# COCO Dataset labels\n",
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '', '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat',\n",
    "    'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',\n",
    "    'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',\n",
    "    'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle',\n",
    "    'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich',\n",
    "    'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "    'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "# Directory containing the synthetic images\n",
    "IMAGE_DIR = \"C:\\\\Users\\\\chari\\\\Downloads\\\\staticMetricsOutputs\"\n",
    "\n",
    "# Load models with updated weights parameter\n",
    "faster_rcnn = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT).eval()\n",
    "ssd = ssd300_vgg16(weights=SSD300_VGG16_Weights.DEFAULT).eval()\n",
    "\n",
    "# Load images and prepare inputs\n",
    "image_tensors = []\n",
    "image_names = []\n",
    "\n",
    "for img_name in os.listdir(IMAGE_DIR):\n",
    "    if img_name.endswith(\".png\"):  # Assuming the images are in PNG format\n",
    "        img_path = os.path.join(IMAGE_DIR, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        img_tensor = F.to_tensor(img)\n",
    "        image_tensors.append(img_tensor)\n",
    "        image_names.append(img_name)\n",
    "\n",
    "# Ground truth data for testing (manual assignment based on image labels)\n",
    "ground_truths = {\n",
    "    'giraffe.png': [25],\n",
    "    'bench.png': [15],           \n",
    "    'elephant.png': [22],         \n",
    "}\n",
    "\n",
    "# Metrics storage for accuracy per image\n",
    "faster_rcnn_accuracies = []\n",
    "ssd_accuracies = []\n",
    "\n",
    "# Helper function to filter predictions based on confidence threshold\n",
    "def get_filtered_predictions(predictions, scores, threshold=0.5):\n",
    "    \"\"\"Filter predictions based on confidence score threshold.\"\"\"\n",
    "    valid_preds = []\n",
    "    for i in range(len(predictions)):\n",
    "        if scores[i] >= threshold:\n",
    "            valid_preds.append(predictions[i])\n",
    "    return valid_preds\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(ground_truth_labels, predicted_labels):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    if len(predicted_labels) == 0:  # No predictions made\n",
    "        return 0  # Return 0 for no predictions\n",
    "\n",
    "    if len(ground_truth_labels) != len(predicted_labels):\n",
    "        # If number of predictions doesn't match the ground truth, return 0\n",
    "        return 0\n",
    "\n",
    "    # Compute accuracy\n",
    "    return accuracy_score(ground_truth_labels, predicted_labels)\n",
    "\n",
    "# Function to visualize predictions on the image\n",
    "def visualize_predictions(image, boxes, scores, labels, model_name):\n",
    "    \"\"\"Overlay bounding boxes, labels, and scores on the image.\"\"\"\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        if score > 0.5:  # Only display detections with confidence > 0.5\n",
    "            if label < len(COCO_INSTANCE_CATEGORY_NAMES):\n",
    "                label_name = COCO_INSTANCE_CATEGORY_NAMES[label]\n",
    "            else:\n",
    "                label_name = \"Unknown\"\n",
    "            box = [int(coord) for coord in box]\n",
    "            draw.rectangle(box, outline=\"red\", width=3)\n",
    "            draw.text((box[0], box[1]), f\"{label_name} {score:.2f}\", fill=\"red\")\n",
    "    return image\n",
    "\n",
    "# Run inference and visualize\n",
    "with torch.no_grad():\n",
    "    for i, img_tensor in enumerate(image_tensors):\n",
    "        img_name = image_names[i]\n",
    "        img_path = os.path.join(IMAGE_DIR, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")  # Reload image for visualization\n",
    "\n",
    "        print(f\"Processing image: {img_name}\")\n",
    "\n",
    "        # Faster R-CNN\n",
    "        faster_rcnn_output = faster_rcnn([img_tensor])[0]\n",
    "        faster_rcnn_boxes = faster_rcnn_output['boxes'].cpu().numpy()\n",
    "        faster_rcnn_scores = faster_rcnn_output['scores'].cpu().numpy()\n",
    "        faster_rcnn_labels = faster_rcnn_output['labels'].cpu().numpy()\n",
    "\n",
    "        # SSD\n",
    "        ssd_output = ssd([img_tensor])[0]\n",
    "        ssd_boxes = ssd_output['boxes'].cpu().numpy()\n",
    "        ssd_scores = ssd_output['scores'].cpu().numpy()\n",
    "        ssd_labels = ssd_output['labels'].cpu().numpy()\n",
    "\n",
    "        # Retrieve ground truth\n",
    "        ground_truth_labels = ground_truths.get(img_name, [])\n",
    "\n",
    "        # Filter predictions for valid detections (confidence threshold)\n",
    "        faster_rcnn_filtered = get_filtered_predictions(faster_rcnn_labels, faster_rcnn_scores, threshold=0.5)\n",
    "        ssd_filtered = get_filtered_predictions(ssd_labels, ssd_scores, threshold=0.5)\n",
    "\n",
    "        # Calculate accuracy for Faster R-CNN\n",
    "        faster_rcnn_accuracy = calculate_accuracy(ground_truth_labels, faster_rcnn_filtered)\n",
    "        faster_rcnn_accuracies.append(faster_rcnn_accuracy)\n",
    "\n",
    "        # Calculate accuracy for SSD\n",
    "        ssd_accuracy = calculate_accuracy(ground_truth_labels, ssd_filtered)\n",
    "        ssd_accuracies.append(ssd_accuracy)\n",
    "\n",
    "        # Visualize Faster R-CNN predictions\n",
    "        faster_rcnn_img = visualize_predictions(img.copy(), faster_rcnn_boxes, faster_rcnn_scores, faster_rcnn_labels, \"Faster R-CNN\")\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(faster_rcnn_img)\n",
    "        plt.title(f\"Faster R-CNN Predictions for {img_name}\")\n",
    "        plt.show()\n",
    "\n",
    "        # Visualize SSD predictions\n",
    "        ssd_img = visualize_predictions(img.copy(), ssd_boxes, ssd_scores, ssd_labels, \"SSD\")\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(ssd_img)\n",
    "        plt.title(f\"SSD Predictions for {img_name}\")\n",
    "        plt.show()\n",
    "\n",
    "# Calculate mean accuracy for Faster R-CNN and SSD\n",
    "mean_faster_rcnn_accuracy = np.mean(faster_rcnn_accuracies)\n",
    "mean_ssd_accuracy = np.mean(ssd_accuracies)\n",
    "\n",
    "# Print the overall mean accuracy for both models\n",
    "print(f\"Overall Mean Accuracy for Faster R-CNN: {mean_faster_rcnn_accuracy:.4f}\")\n",
    "print(f\"Overall Mean Accuracy for SSD: {mean_ssd_accuracy:.4f}\")\n",
    "\n",
    "# Plot accuracy comparison for both models\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Bar chart for mean accuracy comparison\n",
    "models = ['Faster R-CNN', 'SSD']\n",
    "accuracies = [mean_faster_rcnn_accuracy, mean_ssd_accuracy]\n",
    "\n",
    "ax.bar(models, accuracies, color=['red', 'blue'])\n",
    "\n",
    "ax.set_ylabel('Mean Accuracy')\n",
    "ax.set_title('Comparison of Mean Accuracy between Faster R-CNN and SSD')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cc6edd-0546-4729-bcc4-3eccca1e152f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
